{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO \n",
    "##### Advertencia: este notebook es una recopilacion/guia del trabajo realizado en el modelo final, se muestra el proceso realizado paso a paso, pero por motivos de rendimiento el numero de epocas se ha reducido a 2. en caso de uso elevar el numero de replicas a 100 como se usa en el modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 17 11:54:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.16                 Driver Version: 572.16         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   41C    P0             22W /   84W |       0MiB /   8192MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos la configuración de la tarjeta Nvidia y CUDA\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75  Python-3.11.7 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "Setup complete  (20 CPUs, 31.7 GB RAM, 94.4/952.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos la implementación y versión de Yolo  \n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos la librerias necesarias \n",
    "from ultralytics import YOLO \n",
    "from IPython.display import Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Facial-Emotion-Dataset--3 to yolov11:: 100%|██████████| 41002/41002 [00:02<00:00, 16520.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Facial-Emotion-Dataset--3 in yolov11:: 100%|██████████| 2466/2466 [00:00<00:00, 2824.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#instalamos la libreria que vamos a usar de Roboflow haciendo una llamada a su API\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"KwEwzKgU4TML4BZUrgNJ\")\n",
    "project = rf.workspace(\"workenv-dayet\").project(\"facial-emotion-dataset-7g1jd-hipbk\")\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\borja\\\\Desktop\\\\data science\\\\personal\\\\repositorios\\\\MoodLens\\\\aproximaciones\\\\Yolov11\\\\Facial-Emotion-Dataset--3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Buscamos la localización de nuestro data set \n",
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#para google colabs\n",
    "#task = detect \n",
    "#mode = train \n",
    "#data= {dataset.location}/data.yaml \n",
    "#model= 'yolo11n.pt'\n",
    "#epoch = 10 \n",
    "#imgz = 640 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.75  Python-3.11.7 torch-2.6.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3070 Ti Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\data.yaml, epochs=2, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset 'C://Users/borja/Desktop/data_science/bootcamp/entregas/ML/emociones/proyecto prueba 1/Facial-Emotion-Dataset--3/data.yaml' error  'C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\data.yaml' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:564\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myml\u001b[39m\u001b[38;5;124m\"\u001b[39m} \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    562\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    563\u001b[0m }:\n\u001b[1;32m--> 564\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_det_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\data\\utils.py:316\u001b[0m, in \u001b[0;36mcheck_det_dataset\u001b[1;34m(dataset, autodownload)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;124;03mDownload, verify, and/or unzip a dataset if not found locally.\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;124;03m    (dict): Parsed dataset information and paths.\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 316\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# Download (optional)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\checks.py:522\u001b[0m, in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix, download, download_dir, hard)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files \u001b[38;5;129;01mand\u001b[39;00m hard:\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(files) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hard:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 'C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\data.yaml' does not exist",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mborja\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata_science\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mbootcamp\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mentregas\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mML\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43memociones\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mproyecto prueba 1\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mFacial-Emotion-Dataset--3\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:803\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    801\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt_path\n\u001b[1;32m--> 803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_smart_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_callbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresume\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# manually set model only if not resuming\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mget_model(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39myaml)\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:134\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m check_model_file_from_stem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mmodel)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(LOCAL_RANK):  \u001b[38;5;66;03m# avoid auto-downloading dataset multiple times\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtestset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Optimization utils init\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:568\u001b[0m, in \u001b[0;36mBaseTrainer.get_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myaml_file\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# for validating 'yolo train data=url.zip' usage\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(emojis(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclean_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m error ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m data\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Dataset 'C://Users/borja/Desktop/data_science/bootcamp/entregas/ML/emociones/proyecto prueba 1/Facial-Emotion-Dataset--3/data.yaml' error  'C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\data.yaml' does not exist"
     ]
    }
   ],
   "source": [
    "#cargamos la libreria Yolo\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Cargarmos el modelo\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.train(data='C:\\\\Users\\\\borja\\\\Desktop\\\\data_science\\\\bootcamp\\\\entregas\\\\ML\\\\emociones\\\\proyecto prueba 1\\\\Facial-Emotion-Dataset--3\\\\data.yaml', epochs=2, imgsz=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'runs\\\\detect\\\\train2\\\\weights\\\\best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Para validar tu modelo entrenado\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar el modelo mejor entrenado\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/detect/train2/weights/best.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Ajusta la ruta si es diferente\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Validar el modelo\u001b[39;00m\n\u001b[0;32m      7\u001b[0m metrics \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:147\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:290\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    287\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:900\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    902\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:827\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m    825\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\utils\\patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\borja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs\\\\detect\\\\train2\\\\weights\\\\best.pt'"
     ]
    }
   ],
   "source": [
    "#Para validar tu modelo entrenado\n",
    "\n",
    "# Cargar el modelo mejor entrenado\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")  # Ajusta la ruta si es diferente\n",
    "\n",
    "# Validar el modelo\n",
    "metrics = model.val()\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\1-5-_jpg.rf.fedd78c04d11645905c4124fa52aaa17.jpg: 640x640 (no detections), 119.4ms\n",
      "image 2/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\1-7-_jpg.rf.e66429ccfa57cb2c03c5e06fe43e3a8b.jpg: 640x640 (no detections), 100.9ms\n",
      "image 3/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\1-8-_jpg.rf.d4579ef9e8b6ca750aa61bd65ff33b47.jpg: 640x640 (no detections), 93.2ms\n",
      "image 4/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\10_jpg.rf.ce00a096968d9ce9ceb0a85b39e601cb.jpg: 640x640 1 fear, 3 happys, 1 neutral, 92.2ms\n",
      "image 5/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\14_jpg.rf.26f69d5d4bfeffe1665b1558c11f95e9.jpg: 640x640 2 fears, 1 happy, 68.4ms\n",
      "image 6/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\2-3-_jpg.rf.2d5cb265aa6d734ebfffb7612bb0386c.jpg: 640x640 (no detections), 69.5ms\n",
      "image 7/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\2-6-_jpg.rf.afbfed74fccbace3c3619944e33c8388.jpg: 640x640 (no detections), 63.3ms\n",
      "image 8/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\2-6-_jpg.rf.df80d63bbd5782624e10d074acd40752.jpg: 640x640 (no detections), 63.1ms\n",
      "image 9/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\2-7-_jpg.rf.025d777aeb48bf33ae5b840cdb33ed8d.jpg: 640x640 (no detections), 70.9ms\n",
      "image 10/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\2-9-_jpg.rf.04a786121cb59fea3f6cac791f580441.jpg: 640x640 (no detections), 76.6ms\n",
      "image 11/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\20_jpg.rf.c192687d03793b9c8925976b691550f1.jpg: 640x640 1 fear, 2 happys, 71.1ms\n",
      "image 12/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-10-_jpg.rf.6d2af72375ee156883544e9f9cebccb1.jpg: 640x640 (no detections), 79.2ms\n",
      "image 13/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-10-_jpg.rf.a8f617bff90d41ba4d04ba06e6d0f468.jpg: 640x640 1 surprise, 79.3ms\n",
      "image 14/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-10-_jpg.rf.bee93649a91b0d9c66cf1e7ccf1101cc.jpg: 640x640 (no detections), 83.7ms\n",
      "image 15/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-2-_jpg.rf.b12178da04826a21811d66693a14b7a7.jpg: 640x640 1 surprise, 76.3ms\n",
      "image 16/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-5-_jpg.rf.9297e1a3ff6b26c6ea625cb8d57f237e.jpg: 640x640 (no detections), 73.9ms\n",
      "image 17/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-8-_jpg.rf.2ef687a3447f1bc672ea613b72267e1a.jpg: 640x640 (no detections), 73.2ms\n",
      "image 18/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-8-_jpg.rf.9dfa14594d358f1037b3e9fdcb961163.jpg: 640x640 1 surprise, 72.8ms\n",
      "image 19/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-8-_jpg.rf.ed189205ef81023e5c9855adeae28e6d.jpg: 640x640 (no detections), 72.9ms\n",
      "image 20/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3-9-_jpg.rf.b13e17ea3987dafff24a89c3f91fcab0.jpg: 640x640 (no detections), 68.8ms\n",
      "image 21/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\38_jpg.rf.7a152ff4cb035b563076e179b8ebcf38.jpg: 640x640 1 angry, 1 fear, 4 happys, 67.5ms\n",
      "image 22/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3_jpg.rf.e99c66abdbb6c862ba090d722a815158.jpg: 640x640 1 angry, 1 fear, 2 happys, 1 neutral, 76.2ms\n",
      "image 23/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\3_jpg.rf.f77a3e7dc9dbc56825adf82ea4b8fed7.jpg: 640x640 (no detections), 73.7ms\n",
      "image 24/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\50_jpg.rf.64fcd205abcb93ea3b716bb1609dd520.jpg: 640x640 1 angry, 1 fear, 2 happys, 75.1ms\n",
      "image 25/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\51_jpg.rf.8c6745c7251e78a0d974f0bb5ea04267.jpg: 640x640 1 fear, 1 happy, 1 neutral, 70.4ms\n",
      "image 26/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\62_jpg.rf.8891a7c2a1b47436ae9b712156bb4cd4.jpg: 640x640 1 angry, 1 fear, 4 happys, 73.5ms\n",
      "image 27/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\62_jpg.rf.cc7a333da1552a81ae9d488e47e23303.jpg: 640x640 2 fears, 3 happys, 77.0ms\n",
      "image 28/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\63_jpg.rf.0ff1aa61e619f28dc03442caf974dbe4.jpg: 640x640 2 fears, 2 happys, 79.5ms\n",
      "image 29/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\64_jpg.rf.81dc4050d8d6a7051185efbf45450bd4.jpg: 640x640 3 happys, 77.6ms\n",
      "image 30/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\65_jpg.rf.410b304009a2e0973e223ac1d3a1a81b.jpg: 640x640 2 angrys, 3 fears, 1 happy, 81.1ms\n",
      "image 31/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\68_jpg.rf.7d122bdd06199b27539a203f0c152eb7.jpg: 640x640 1 angry, 1 fear, 3 happys, 75.5ms\n",
      "image 32/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\72_jpg.rf.eb16997ecbc56f064f84701e1cea0602.jpg: 640x640 1 angry, 2 fears, 7 happys, 66.9ms\n",
      "image 33/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\74_jpg.rf.6e33ca53ae394200f39b5137a2bbca30.jpg: 640x640 1 angry, 5 happys, 68.4ms\n",
      "image 34/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\9_jpg.rf.1e8fac0dbd47b2072c046b5e2d53a94b.jpg: 640x640 2 angrys, 67.4ms\n",
      "image 35/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0016_SU04WH_F2D_png_jpg.rf.434ba1cc12da56b7c60e4cc27aad9c58.jpg: 640x640 1 surprise, 71.2ms\n",
      "image 36/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0019_DI02AE_F2D_png_jpg.rf.cbd6f25b31894b27af1fbe9e7742a127.jpg: 640x640 1 disgust, 68.8ms\n",
      "image 37/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0029_DI02WH_F2D_png_jpg.rf.00b11681f686aeaedc2078975521365d.jpg: 640x640 1 disgust, 76.7ms\n",
      "image 38/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0030_FE04BL_F2D_png_jpg.rf.bc233baa5e1e7b2857d934597ff088f2.jpg: 640x640 1 surprise, 78.5ms\n",
      "image 39/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0030_HA01BL_F2D_png_jpg.rf.c40f871ff679f83789bd832df8386b7b.jpg: 640x640 1 disgust, 69.4ms\n",
      "image 40/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0034_SU03WH_F2D_png_jpg.rf.0f44681670d340eabd0d200ba5ade2de.jpg: 640x640 1 surprise, 66.7ms\n",
      "image 41/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0044_SU04LA_F2D_png_jpg.rf.05702ce01ccb8ee2da141f3c1e64bf10.jpg: 640x640 1 surprise, 68.4ms\n",
      "image 42/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0056_DI01LA_F2D_png_jpg.rf.4e1e1823b8e27403b7f008313978976d.jpg: 640x640 1 disgust, 69.0ms\n",
      "image 43/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0056_DI01LA_F2D_png_jpg.rf.987281f4eabfddd22cad6f993aa16075.jpg: 640x640 1 disgust, 68.3ms\n",
      "image 44/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0056_SU01LA_F2D_png_jpg.rf.4f14a7325567975967502fbda6d10f8b.jpg: 640x640 1 surprise, 66.8ms\n",
      "image 45/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\F0056_SU01LA_F2D_png_jpg.rf.879267014e0dc2bb87842de829cbac95.jpg: 640x640 1 surprise, 67.6ms\n",
      "image 46/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\H186_jpg.rf.536729e37a855bc161b1fc614544f1d5.jpg: 640x640 (no detections), 68.0ms\n",
      "image 47/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\H286_jpg.rf.040bf248d5d5d82a4b6c9dc3b2f21119.jpg: 640x640 (no detections), 67.3ms\n",
      "image 48/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\H294_jpg.rf.b508653d39e906dc8b3a9e5150193a35.jpg: 640x640 (no detections), 70.0ms\n",
      "image 49/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0001_SU03AM_F2D_png_jpg.rf.52b95ba73d8fd2d6c411f7b5533ebee1.jpg: 640x640 1 disgust, 1 surprise, 69.5ms\n",
      "image 50/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0004_DI02WH_F2D_png_jpg.rf.5e4c6c4825d1eac75230d8f1069508eb.jpg: 640x640 1 disgust, 70.8ms\n",
      "image 51/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0006_AN03AE_F2D_png_jpg.rf.9f8269b5c5dbe062b354d02e6970d589.jpg: 640x640 1 angry, 1 sad, 68.0ms\n",
      "image 52/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0008_AN02WH_F2D_png_jpg.rf.342c5bd9e78608852a00a590c1226d09.jpg: 640x640 1 angry, 66.9ms\n",
      "image 53/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0009_AN01WH_F2D_png_jpg.rf.ae8efb322213d8ca301df536a20bc3d2.jpg: 640x640 1 angry, 1 sad, 63.0ms\n",
      "image 54/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0010_SU04AE_F2D_png_jpg.rf.2d67b174399ef334b19251f95ba77b57.jpg: 640x640 1 surprise, 61.7ms\n",
      "image 55/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0011_AN02WH_F2D_png_jpg.rf.e8252518685b9fd2d2db642cd6f9d335.jpg: 640x640 1 angry, 63.8ms\n",
      "image 56/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0011_DI01WH_F2D_png_jpg.rf.39716c10d6aaa2d4eff3a2bff1fdd2df.jpg: 640x640 1 disgust, 61.0ms\n",
      "image 57/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0011_DI04WH_F2D_png_jpg.rf.7052e0cf8813d6c80f05d4b9f59f268a.jpg: 640x640 1 disgust, 60.9ms\n",
      "image 58/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0011_SA02WH_F2D_png_jpg.rf.2f41b5cc49f3e4aea9b5b8b4952da230.jpg: 640x640 1 angry, 61.8ms\n",
      "image 59/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0014_DI02WH_F2D_png_jpg.rf.94cb866fc6e93c94d1b267697c535fe3.jpg: 640x640 1 disgust, 62.5ms\n",
      "image 60/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0015_AN03WH_F2D_png_jpg.rf.166e655403eca13690079f3103d044cd.jpg: 640x640 1 disgust, 62.2ms\n",
      "image 61/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0016_SA04WH_F2D_png_jpg.rf.445bfb210f05281bb677f7a1431cb6d0.jpg: 640x640 1 angry, 66.0ms\n",
      "image 62/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0017_AN03WH_F2D_png_jpg.rf.98fe82bfb043791c2e5b9dc136022259.jpg: 640x640 1 angry, 69.7ms\n",
      "image 63/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0018_AN04WH_F2D_png_jpg.rf.7d4de04f032249529f80c862717d0334.jpg: 640x640 (no detections), 67.1ms\n",
      "image 64/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0019_AN04IN_F2D_png_jpg.rf.4801e9aa0590b2896d486322636b53a0.jpg: 640x640 (no detections), 66.5ms\n",
      "image 65/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0019_DI04IN_F2D_png_jpg.rf.f44017b58c674da9c12f752e348ed729.jpg: 640x640 1 disgust, 66.9ms\n",
      "image 66/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0019_SU03IN_F2D_png_jpg.rf.8ac22ce1f610432865658dc4136426aa.jpg: 640x640 1 surprise, 61.5ms\n",
      "image 67/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0020_SA01IN_F2D_png_jpg.rf.b0f3fe05d3fb33b7648d3f8139a62e4f.jpg: 640x640 (no detections), 62.7ms\n",
      "image 68/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0021_SA03WH_F2D_png_jpg.rf.f700b4d4341ab2cb92ae562262e4293a.jpg: 640x640 1 angry, 1 sad, 65.8ms\n",
      "image 69/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0021_SA04WH_F2D_png_jpg.rf.82f12bcd7508cc28c94f082229e5e2ef.jpg: 640x640 1 angry, 1 sad, 63.9ms\n",
      "image 70/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0022_SU01WH_F2D_png_jpg.rf.223c6c533fdb94fc7a9adb062a19bb7e.jpg: 640x640 1 surprise, 62.8ms\n",
      "image 71/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0023_SA03IN_F2D_png_jpg.rf.ba16fb42b084c1bf7a3abe8c4d8dd363.jpg: 640x640 (no detections), 62.9ms\n",
      "image 72/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0024_AN04AE_F2D_png_jpg.rf.392a8840b3de29bca4576faff9c574e6.jpg: 640x640 (no detections), 62.1ms\n",
      "image 73/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0026_AN04AE_F2D_png_jpg.rf.1c19ca69b02f0d83adc628340a103070.jpg: 640x640 (no detections), 62.3ms\n",
      "image 74/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0027_SA04AE_F2D_png_jpg.rf.bcc33f0a287d95a5b4298c1c3b1fc411.jpg: 640x640 1 angry, 1 sad, 62.1ms\n",
      "image 75/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0035_AN04WH_F2D_png_jpg.rf.8bf187724473fc7f4bace6ef839b15dd.jpg: 640x640 1 angry, 1 sad, 66.9ms\n",
      "image 76/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0036_SA03WH_F2D_png_jpg.rf.a3116de1fad5b0ddf1f6573d521ab087.jpg: 640x640 1 angry, 66.9ms\n",
      "image 77/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0039_AN03AE_F2D_png_jpg.rf.e84166b03ef06f2f7eaa882f4cf2246c.jpg: 640x640 1 angry, 60.5ms\n",
      "image 78/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\M0039_SA02AE_F2D_png_jpg.rf.ff36beef658f2438da1cfb62ffc4239c.jpg: 640x640 1 angry, 62.3ms\n",
      "image 79/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\S252_jpg.rf.ff546ebe3afe6a13055f73995781a0ed.jpg: 640x640 1 happy, 61.4ms\n",
      "image 80/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\angry_1014_jpg.rf.3496d515f89bd63678d0b79790396808.jpg: 640x640 1 angry, 61.2ms\n",
      "image 81/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\angry_1027_jpg.rf.248f9731e3ccc30d31abf2414610e23b.jpg: 640x640 1 angry, 61.2ms\n",
      "image 82/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\angry_314_jpg.rf.dc883a135a48306cf23577173c174d00.jpg: 640x640 (no detections), 62.7ms\n",
      "image 83/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\angry_363_jpg.rf.834838332e704831c4792f363e3cb969.jpg: 640x640 1 angry, 63.2ms\n",
      "image 84/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs023_E_DISGUST_0_png_jpg.rf.aafb298f35772ad0cb2742fda277d198.jpg: 640x640 (no detections), 62.2ms\n",
      "image 85/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs031_E_DISGUST_0_png_jpg.rf.bf3ea0be4a8a716e0a0e08ff53ef12ef.jpg: 640x640 (no detections), 62.1ms\n",
      "image 86/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs040_E_ANGER_0_png_jpg.rf.82daa1b26f001166a9f717cb3cc5bff6.jpg: 640x640 (no detections), 61.5ms\n",
      "image 87/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs040_N_N_0_png_jpg.rf.45711e461d4e4458688e53a6c24f39f8.jpg: 640x640 (no detections), 63.3ms\n",
      "image 88/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs072_E_HAPPY_0_png_jpg.rf.90df10caebbe912b7d13f88da3179e36.jpg: 640x640 (no detections), 61.9ms\n",
      "image 89/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs082_E_ANGER_0_png_jpg.rf.4855c374fc972ad341ebb84857705e2e.jpg: 640x640 (no detections), 61.2ms\n",
      "image 90/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs082_E_DISGUST_0_png_jpg.rf.fc89682adfb4b6ddccc29becbdf51e2d.jpg: 640x640 (no detections), 63.0ms\n",
      "image 91/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs103_N_N_1_png_jpg.rf.a4ed74de696b91fa1a7080d617c85209.jpg: 640x640 1 neutral, 61.5ms\n",
      "image 92/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\bs103_N_N_2_png_jpg.rf.b167d475b6d433ef6a4ae69f934e781f.jpg: 640x640 1 neutral, 62.0ms\n",
      "image 93/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\happy19_jpg.rf.175a9a512c67e089911855b918562d24.jpg: 640x640 (no detections), 61.8ms\n",
      "image 94/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-32-01_jpg.rf.4fe7b14f2ea19816f5c2fc6ac96ed7f6.jpg: 640x640 1 angry, 1 fear, 3 happys, 66.8ms\n",
      "image 95/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-33-55_jpg.rf.721bca893c1e2801b9df11984277e739.jpg: 640x640 1 angry, 5 fears, 2 happys, 67.0ms\n",
      "image 96/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-38-05_jpg.rf.8098cea3cfbf6a7f4d041e588799fa9f.jpg: 640x640 1 fear, 3 happys, 66.0ms\n",
      "image 97/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-50-44_jpg.rf.521faf46450858a87f835cffdbc5afef.jpg: 640x640 1 angry, 2 fears, 4 happys, 1 neutral, 63.2ms\n",
      "image 98/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-54-51_jpg.rf.37a7e8be804ba85a2eca8c956424f5c0.jpg: 640x640 1 angry, 2 fears, 3 happys, 64.0ms\n",
      "image 99/99 C:\\Users\\borja\\Desktop\\data_science\\bootcamp\\entregas\\ML\\emociones\\proyecto prueba 1\\Facial-Emotion-Dataset--3\\test\\images\\pixiz-06-12-2022-14-55-37_jpg.rf.e0a6565c021a71831e47fb31921b2695.jpg: 640x640 2 fears, 2 happys, 61.4ms\n",
      "Speed: 2.2ms preprocess, 68.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "#inferencia \n",
    "\n",
    "\n",
    "# Carga el modelo entrenado\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")\n",
    "\n",
    "# Realiza la inferencia en una imagen\n",
    "results = model('C:\\\\Users\\\\borja\\\\Desktop\\\\data_science\\\\bootcamp\\\\entregas\\\\ML\\\\emociones\\\\proyecto prueba 1\\\\Facial-Emotion-Dataset--3\\\\test\\\\images\\\\', imgsz=640, conf=0.5)\n",
    "\n",
    "# Muestra los resultados\n",
    "for result in results:\n",
    "    result.save('output.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
