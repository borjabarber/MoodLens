{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extracción de Características:\n",
    "Las primeras etapas de la red están diseñadas para aprender características relevantes de las imágenes. Para ello, usaremos capas convolucionales, que son esenciales en el procesamiento de imágenes.\n",
    "\n",
    "### Capas Convolucionales:  \n",
    "\n",
    "Las capas convolucionales (Conv2D) se encargan de aplicar filtros (o \"kernels\") a las imágenes de entrada. Estos filtros recorren la imagen y detectan patrones como bordes, texturas o formas. Cada filtro tiene un tamaño, como 3x3 o 5x5, que determina el área de la imagen que se analizará en cada paso.\n",
    "#### ¿Por qué 3x3 o 5x5?  \n",
    "\n",
    "Los filtros más pequeños como 3x3 son comunes porque son eficientes y permiten combinar varias capas para captar información a diferentes escalas (por ejemplo, una capa convolucional con filtros pequeños puede capturar detalles finos, mientras que una capa más profunda puede captar patrones más grandes).\n",
    "\n",
    "### Normalización por lotes (BatchNormalization):\n",
    "\n",
    "La función `BatchNormalization()` estabiliza el proceso de entrenamiento al normalizar las activaciones de cada capa. Esto ayuda a que la red converja más rápido y sea menos sensible a las inicializaciones de los pesos.\n",
    "\n",
    "### Función de Activación ReLU:\n",
    "\n",
    "Después de aplicar los filtros, las activaciones de las neuronas se pasan por una función de activación, que introduce no linealidad en la red. En este caso, usamos ReLU (Rectified Linear Unit), que toma el valor máximo entre cero y el valor de la activación. Esto permite que la red aprenda patrones más complejos.\n",
    "\n",
    "### Max Pooling (MaxPool2D):\n",
    "\n",
    "La operación de `MaxPool2D(pool_size=(2,2))` reduce la dimensionalidad de las activaciones. Es decir, toma el valor máximo de cada bloque de 2x2 píxeles, lo que ayuda a que la red no sea tan sensible a pequeñas variaciones en la imagen y a reducir la cantidad de cálculos. Esto se conoce como \"reducción de resolución\".\n",
    "\n",
    "### Dropout:\n",
    "`Dropout(0.2)` es una técnica para prevenir el sobreajuste (overfitting). Durante el entrenamiento, esta capa \"apaga\" aleatoriamente un 20% de las neuronas, lo que obliga a la red a no depender demasiado de ninguna neurona específica y, por lo tanto, mejora la generalización.\n",
    "\n",
    "# 2. Clasificación:\n",
    "Después de que la red haya aprendido las características de las imágenes, necesitamos pasar esta información a una red completamente conectada (o capas densas) para hacer una predicción.\n",
    "\n",
    "### Aplanamiento (Flatten):\n",
    "\n",
    "La salida de la última capa convolucional generalmente tiene varias dimensiones (por ejemplo, ancho, alto, canales). Para pasarla a una capa densa, necesitamos \"aplanarla\", es decir, convertir esas dimensiones en un vector de una sola dimensión. Esto se hace con la capa `Flatten()`.\n",
    "\n",
    "### Capas Densas (Dense):\n",
    "\n",
    "Estas capas están completamente conectadas entre sí. A diferencia de las capas convolucionales, donde cada neurona solo ve una parte de la entrada, en las capas densas cada neurona está conectada a todas las neuronas de la capa anterior. Esto permite que la red aprenda combinaciones complejas de las características extraídas.\n",
    "\n",
    "### Capa de salida (Softmax):\n",
    "\n",
    "Finalmente, para hacer la clasificación, en la capa de salida usamos la función de activación softmax. Esta función convierte las salidas de la red en probabilidades. Si tienes varias clases (por ejemplo, categorías de imágenes), softmax garantiza que la suma de las probabilidades sea 1 y selecciona la clase con la probabilidad más alta como la predicción final.\n",
    "\n",
    "# 3. Compilación y Entrenamiento:\n",
    "### Función de Pérdida (categorical_crossentropy):\n",
    "\n",
    "Dado que estamos tratando con un problema de clasificación multiclase, usamos `categorical_crossentropy` como función de pérdida. Esta función mide cuán lejos está la predicción de la red de la verdad real (etiqueta de la imagen). El objetivo es minimizar esta pérdida.\n",
    "\n",
    "### Optimizador (Adam):\n",
    "\n",
    "Adam es un algoritmo de optimización que ajusta los pesos de la red para minimizar la función de pérdida. Combina los mejores aspectos de otros optimizadores como Momentum y Adagrad, y es muy popular debido a su eficiencia y velocidad. El parámetro 1e-4 representa la tasa de aprendizaje, que controla qué tan grandes son los pasos dados por el optimizador para ajustar los pesos.\n",
    "\n",
    "### Métrica de Evaluación (accuracy):\n",
    "### ¿Qué hace?\n",
    "Durante el entrenamiento, queremos monitorear cuán bien está funcionando la red. Usamos la precisión (`accuracy`) como métrica, que mide la proporción de predicciones correctas en comparación con el total de predicciones.\n",
    "\n",
    "### Resumen:\n",
    "- **Extracción de características**: Varias capas convolucionales (Conv2D), seguidas de normalización, activaciones y reducción de dimensiones.\n",
    "- **Clasificación**: Aplanado de las salidas, seguido de capas densas y una capa de salida con softmax.\n",
    "- **Entrenamiento**: Usamos `categorical_crossentropy` como pérdida, Adam para optimización, y `accuracy` para medir el rendimiento.\n",
    "\n",
    "Esta arquitectura es bastante común y eficaz para tareas de conputer vision, como clasificación de imágenes.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
